{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2c69c6-37f7-49d8-add5-a42e491f7754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:06:54.269459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-16 20:06:54.269505: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-16 20:06:54.270332: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-16 20:06:54.276555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 20:06:55.146724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4b7bfa-1277-4ad5-8467-12bfcb508452",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/data/02_training_data/'\n",
    "MODEL_OUT_PATH = '/data/03_models/relation_classifier/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3400e-1c9c-4d96-90df-a9990f1644f3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe09519-3c33-496e-8a42-529a651bc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_parquet(os.path.join(DATA_PATH,'temp_train_df.pq'))\n",
    "    test_df = pd.read_parquet(os.path.join(DATA_PATH,'temp_test_df.pq'))\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac3f95-238f-47fd-b1cd-eaea66d10a68",
   "metadata": {},
   "source": [
    "### Filter to relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e70ab3e-8d46-42a6-bd0c-99899fa226ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['type_of_regulation', 'text_prep', 'srna_name_mentioned', 'gene_name_mentioned']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35c994c-bbad-4660-8aca-3fbdca29c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['type_of_regulation', 'text_prep', 'srna_name_mentioned', 'gene_name_mentioned']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8c7c0-d2b9-4702-b5b0-4e0ea215db06",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4024568c-b322-4e9d-aafa-ff28b257f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df['labels']=le.fit_transform(train_df['type_of_regulation'])\n",
    "test_df['labels'] = le.transform(test_df['type_of_regulation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09625c9c-138c-4a02-8dd8-3e85f5a3f60c",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11995987-0197-4c8a-8036-686bc52f1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90b6b8-a17b-4175-acac-c79eea13fa05",
   "metadata": {},
   "source": [
    "### Prepare Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebc0941-a71c-47b0-ac5a-005be0054803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(dataframe, tokenizer, max_len=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        # Mark entities in the text\n",
    "        marked_text = f\"{row['text_prep']} [SEP] {row['srna_name_mentioned']} [SEP] {row['gene_name_mentioned']}\"\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            marked_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "047b0cdc-3ae6-46f6-ab1b-566011d354e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "input_ids, attention_masks, labels = preprocess_texts(train_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8157b043-75f2-44c0-a1e0-24b35b1c5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input_ids, validation_attention_masks, validation_labels = preprocess_texts(test_df, tokenizer)\n",
    "\n",
    "validation_data = TensorDataset(validation_input_ids, validation_attention_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0588f-8160-42ba-b43b-a3291f451d09",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae0d720-d5ee-4cb8-b16b-c329ddc2a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(set(train_df[\"type_of_regulation\"]))\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", num_labels=num_labels) # Set num_labels to your number of relation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6ca7c-e0e5-44ff-8a6b-13148d8d896f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d559354-8b47-4301-bab8-49a6331cf727",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e1ca75-a67d-403c-a2e0-d79da3adb4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernards/sRNA_extraction/srna_venv/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 of epoch 0 completed.\n",
      "Step 1 of epoch 0 completed.\n",
      "Step 2 of epoch 0 completed.\n",
      "Step 3 of epoch 0 completed.\n",
      "Step 4 of epoch 0 completed.\n",
      "Step 5 of epoch 0 completed.\n",
      "Step 6 of epoch 0 completed.\n",
      "Step 7 of epoch 0 completed.\n",
      "Step 8 of epoch 0 completed.\n",
      "Step 9 of epoch 0 completed.\n",
      "Step 10 of epoch 0 completed.\n",
      "Step 11 of epoch 0 completed.\n",
      "Step 12 of epoch 0 completed.\n",
      "Step 13 of epoch 0 completed.\n",
      "Step 14 of epoch 0 completed.\n",
      "Step 15 of epoch 0 completed.\n",
      "Step 16 of epoch 0 completed.\n",
      "Step 17 of epoch 0 completed.\n",
      "Step 0 of epoch 1 completed.\n",
      "Step 1 of epoch 1 completed.\n",
      "Step 2 of epoch 1 completed.\n",
      "Step 3 of epoch 1 completed.\n",
      "Step 4 of epoch 1 completed.\n",
      "Step 5 of epoch 1 completed.\n",
      "Step 6 of epoch 1 completed.\n",
      "Step 7 of epoch 1 completed.\n",
      "Step 8 of epoch 1 completed.\n",
      "Step 9 of epoch 1 completed.\n",
      "Step 10 of epoch 1 completed.\n",
      "Step 11 of epoch 1 completed.\n",
      "Step 12 of epoch 1 completed.\n",
      "Step 13 of epoch 1 completed.\n",
      "Step 14 of epoch 1 completed.\n",
      "Step 15 of epoch 1 completed.\n",
      "Step 16 of epoch 1 completed.\n",
      "Step 17 of epoch 1 completed.\n",
      "Step 0 of epoch 2 completed.\n",
      "Step 1 of epoch 2 completed.\n",
      "Step 2 of epoch 2 completed.\n",
      "Step 3 of epoch 2 completed.\n",
      "Step 4 of epoch 2 completed.\n",
      "Step 5 of epoch 2 completed.\n",
      "Step 6 of epoch 2 completed.\n",
      "Step 7 of epoch 2 completed.\n",
      "Step 8 of epoch 2 completed.\n",
      "Step 9 of epoch 2 completed.\n",
      "Step 10 of epoch 2 completed.\n",
      "Step 11 of epoch 2 completed.\n",
      "Step 12 of epoch 2 completed.\n",
      "Step 13 of epoch 2 completed.\n",
      "Step 14 of epoch 2 completed.\n",
      "Step 15 of epoch 2 completed.\n",
      "Step 16 of epoch 2 completed.\n",
      "Step 17 of epoch 2 completed.\n",
      "Step 0 of epoch 3 completed.\n",
      "Step 1 of epoch 3 completed.\n",
      "Step 2 of epoch 3 completed.\n",
      "Step 3 of epoch 3 completed.\n",
      "Step 4 of epoch 3 completed.\n",
      "Step 5 of epoch 3 completed.\n",
      "Step 6 of epoch 3 completed.\n",
      "Step 7 of epoch 3 completed.\n",
      "Step 8 of epoch 3 completed.\n",
      "Step 9 of epoch 3 completed.\n",
      "Step 10 of epoch 3 completed.\n",
      "Step 11 of epoch 3 completed.\n",
      "Step 12 of epoch 3 completed.\n",
      "Step 13 of epoch 3 completed.\n",
      "Step 14 of epoch 3 completed.\n",
      "Step 15 of epoch 3 completed.\n",
      "Step 16 of epoch 3 completed.\n",
      "Step 17 of epoch 3 completed.\n",
      "Step 0 of epoch 4 completed.\n",
      "Step 1 of epoch 4 completed.\n",
      "Step 2 of epoch 4 completed.\n",
      "Step 3 of epoch 4 completed.\n",
      "Step 4 of epoch 4 completed.\n",
      "Step 5 of epoch 4 completed.\n",
      "Step 6 of epoch 4 completed.\n",
      "Step 7 of epoch 4 completed.\n",
      "Step 8 of epoch 4 completed.\n",
      "Step 9 of epoch 4 completed.\n",
      "Step 10 of epoch 4 completed.\n",
      "Step 11 of epoch 4 completed.\n",
      "Step 12 of epoch 4 completed.\n",
      "Step 13 of epoch 4 completed.\n",
      "Step 14 of epoch 4 completed.\n",
      "Step 15 of epoch 4 completed.\n",
      "Step 16 of epoch 4 completed.\n",
      "Step 17 of epoch 4 completed.\n",
      "Step 0 of epoch 5 completed.\n",
      "Step 1 of epoch 5 completed.\n",
      "Step 2 of epoch 5 completed.\n",
      "Step 3 of epoch 5 completed.\n",
      "Step 4 of epoch 5 completed.\n",
      "Step 5 of epoch 5 completed.\n",
      "Step 6 of epoch 5 completed.\n",
      "Step 7 of epoch 5 completed.\n",
      "Step 8 of epoch 5 completed.\n",
      "Step 9 of epoch 5 completed.\n",
      "Step 10 of epoch 5 completed.\n",
      "Step 11 of epoch 5 completed.\n",
      "Step 12 of epoch 5 completed.\n",
      "Step 13 of epoch 5 completed.\n",
      "Step 14 of epoch 5 completed.\n",
      "Step 15 of epoch 5 completed.\n",
      "Step 16 of epoch 5 completed.\n",
      "Step 17 of epoch 5 completed.\n",
      "Step 0 of epoch 6 completed.\n",
      "Step 1 of epoch 6 completed.\n",
      "Step 2 of epoch 6 completed.\n",
      "Step 3 of epoch 6 completed.\n",
      "Step 4 of epoch 6 completed.\n",
      "Step 5 of epoch 6 completed.\n",
      "Step 6 of epoch 6 completed.\n",
      "Step 7 of epoch 6 completed.\n",
      "Step 8 of epoch 6 completed.\n",
      "Step 9 of epoch 6 completed.\n",
      "Step 10 of epoch 6 completed.\n",
      "Step 11 of epoch 6 completed.\n",
      "Step 12 of epoch 6 completed.\n",
      "Step 13 of epoch 6 completed.\n",
      "Step 14 of epoch 6 completed.\n",
      "Step 15 of epoch 6 completed.\n",
      "Step 16 of epoch 6 completed.\n",
      "Step 17 of epoch 6 completed.\n",
      "Step 0 of epoch 7 completed.\n",
      "Step 1 of epoch 7 completed.\n",
      "Step 2 of epoch 7 completed.\n",
      "Step 3 of epoch 7 completed.\n",
      "Step 4 of epoch 7 completed.\n",
      "Step 5 of epoch 7 completed.\n",
      "Step 6 of epoch 7 completed.\n",
      "Step 7 of epoch 7 completed.\n",
      "Step 8 of epoch 7 completed.\n",
      "Step 9 of epoch 7 completed.\n",
      "Step 10 of epoch 7 completed.\n",
      "Step 11 of epoch 7 completed.\n",
      "Step 12 of epoch 7 completed.\n",
      "Step 13 of epoch 7 completed.\n",
      "Step 14 of epoch 7 completed.\n",
      "Step 15 of epoch 7 completed.\n",
      "Step 16 of epoch 7 completed.\n",
      "Step 17 of epoch 7 completed.\n",
      "Step 0 of epoch 8 completed.\n",
      "Step 1 of epoch 8 completed.\n",
      "Step 2 of epoch 8 completed.\n",
      "Step 3 of epoch 8 completed.\n",
      "Step 4 of epoch 8 completed.\n",
      "Step 5 of epoch 8 completed.\n",
      "Step 6 of epoch 8 completed.\n",
      "Step 7 of epoch 8 completed.\n",
      "Step 8 of epoch 8 completed.\n",
      "Step 9 of epoch 8 completed.\n",
      "Step 10 of epoch 8 completed.\n",
      "Step 11 of epoch 8 completed.\n",
      "Step 12 of epoch 8 completed.\n",
      "Step 13 of epoch 8 completed.\n",
      "Step 14 of epoch 8 completed.\n",
      "Step 15 of epoch 8 completed.\n",
      "Step 16 of epoch 8 completed.\n",
      "Step 17 of epoch 8 completed.\n",
      "Step 0 of epoch 9 completed.\n",
      "Step 1 of epoch 9 completed.\n",
      "Step 2 of epoch 9 completed.\n",
      "Step 3 of epoch 9 completed.\n",
      "Step 4 of epoch 9 completed.\n",
      "Step 5 of epoch 9 completed.\n",
      "Step 6 of epoch 9 completed.\n",
      "Step 7 of epoch 9 completed.\n",
      "Step 8 of epoch 9 completed.\n",
      "Step 9 of epoch 9 completed.\n",
      "Step 10 of epoch 9 completed.\n",
      "Step 11 of epoch 9 completed.\n",
      "Step 12 of epoch 9 completed.\n",
      "Step 13 of epoch 9 completed.\n",
      "Step 14 of epoch 9 completed.\n",
      "Step 15 of epoch 9 completed.\n",
      "Step 16 of epoch 9 completed.\n",
      "Step 17 of epoch 9 completed.\n",
      "Step 0 of epoch 10 completed.\n",
      "Step 1 of epoch 10 completed.\n",
      "Step 2 of epoch 10 completed.\n",
      "Step 3 of epoch 10 completed.\n",
      "Step 4 of epoch 10 completed.\n",
      "Step 5 of epoch 10 completed.\n",
      "Step 6 of epoch 10 completed.\n",
      "Step 7 of epoch 10 completed.\n",
      "Step 8 of epoch 10 completed.\n",
      "Step 9 of epoch 10 completed.\n",
      "Step 10 of epoch 10 completed.\n",
      "Step 11 of epoch 10 completed.\n",
      "Step 12 of epoch 10 completed.\n",
      "Step 13 of epoch 10 completed.\n",
      "Step 14 of epoch 10 completed.\n",
      "Step 15 of epoch 10 completed.\n",
      "Step 16 of epoch 10 completed.\n",
      "Step 17 of epoch 10 completed.\n",
      "Step 0 of epoch 11 completed.\n",
      "Step 1 of epoch 11 completed.\n",
      "Step 2 of epoch 11 completed.\n",
      "Step 3 of epoch 11 completed.\n",
      "Step 4 of epoch 11 completed.\n",
      "Step 5 of epoch 11 completed.\n",
      "Step 6 of epoch 11 completed.\n",
      "Step 7 of epoch 11 completed.\n",
      "Step 8 of epoch 11 completed.\n",
      "Step 9 of epoch 11 completed.\n",
      "Step 10 of epoch 11 completed.\n",
      "Step 11 of epoch 11 completed.\n",
      "Step 12 of epoch 11 completed.\n",
      "Step 13 of epoch 11 completed.\n",
      "Step 14 of epoch 11 completed.\n",
      "Step 15 of epoch 11 completed.\n",
      "Step 16 of epoch 11 completed.\n",
      "Step 17 of epoch 11 completed.\n",
      "Step 0 of epoch 12 completed.\n",
      "Step 1 of epoch 12 completed.\n",
      "Step 2 of epoch 12 completed.\n",
      "Step 3 of epoch 12 completed.\n",
      "Step 4 of epoch 12 completed.\n",
      "Step 5 of epoch 12 completed.\n",
      "Step 6 of epoch 12 completed.\n",
      "Step 7 of epoch 12 completed.\n",
      "Step 8 of epoch 12 completed.\n",
      "Step 9 of epoch 12 completed.\n",
      "Step 10 of epoch 12 completed.\n",
      "Step 11 of epoch 12 completed.\n",
      "Step 12 of epoch 12 completed.\n",
      "Step 13 of epoch 12 completed.\n",
      "Step 14 of epoch 12 completed.\n",
      "Step 15 of epoch 12 completed.\n",
      "Step 16 of epoch 12 completed.\n",
      "Step 17 of epoch 12 completed.\n",
      "Step 0 of epoch 13 completed.\n",
      "Step 1 of epoch 13 completed.\n",
      "Step 2 of epoch 13 completed.\n",
      "Step 3 of epoch 13 completed.\n",
      "Step 4 of epoch 13 completed.\n",
      "Step 5 of epoch 13 completed.\n",
      "Step 6 of epoch 13 completed.\n",
      "Step 7 of epoch 13 completed.\n",
      "Step 8 of epoch 13 completed.\n",
      "Step 9 of epoch 13 completed.\n",
      "Step 10 of epoch 13 completed.\n",
      "Step 11 of epoch 13 completed.\n",
      "Step 12 of epoch 13 completed.\n",
      "Step 13 of epoch 13 completed.\n",
      "Step 14 of epoch 13 completed.\n",
      "Step 15 of epoch 13 completed.\n",
      "Step 16 of epoch 13 completed.\n",
      "Step 17 of epoch 13 completed.\n",
      "Step 0 of epoch 14 completed.\n",
      "Step 1 of epoch 14 completed.\n",
      "Step 2 of epoch 14 completed.\n",
      "Step 3 of epoch 14 completed.\n",
      "Step 4 of epoch 14 completed.\n",
      "Step 5 of epoch 14 completed.\n",
      "Step 6 of epoch 14 completed.\n",
      "Step 7 of epoch 14 completed.\n",
      "Step 8 of epoch 14 completed.\n",
      "Step 9 of epoch 14 completed.\n",
      "Step 10 of epoch 14 completed.\n",
      "Step 11 of epoch 14 completed.\n",
      "Step 12 of epoch 14 completed.\n",
      "Step 13 of epoch 14 completed.\n",
      "Step 14 of epoch 14 completed.\n",
      "Step 15 of epoch 14 completed.\n",
      "Step 16 of epoch 14 completed.\n",
      "Step 17 of epoch 14 completed.\n",
      "Step 0 of epoch 15 completed.\n",
      "Step 1 of epoch 15 completed.\n",
      "Step 2 of epoch 15 completed.\n",
      "Step 3 of epoch 15 completed.\n",
      "Step 4 of epoch 15 completed.\n",
      "Step 5 of epoch 15 completed.\n",
      "Step 6 of epoch 15 completed.\n",
      "Step 7 of epoch 15 completed.\n",
      "Step 8 of epoch 15 completed.\n",
      "Step 9 of epoch 15 completed.\n",
      "Step 10 of epoch 15 completed.\n",
      "Step 11 of epoch 15 completed.\n",
      "Step 12 of epoch 15 completed.\n",
      "Step 13 of epoch 15 completed.\n",
      "Step 14 of epoch 15 completed.\n",
      "Step 15 of epoch 15 completed.\n",
      "Step 16 of epoch 15 completed.\n",
      "Step 17 of epoch 15 completed.\n",
      "Step 0 of epoch 16 completed.\n",
      "Step 1 of epoch 16 completed.\n",
      "Step 2 of epoch 16 completed.\n",
      "Step 3 of epoch 16 completed.\n",
      "Step 4 of epoch 16 completed.\n",
      "Step 5 of epoch 16 completed.\n",
      "Step 6 of epoch 16 completed.\n",
      "Step 7 of epoch 16 completed.\n",
      "Step 8 of epoch 16 completed.\n",
      "Step 9 of epoch 16 completed.\n",
      "Step 10 of epoch 16 completed.\n",
      "Step 11 of epoch 16 completed.\n",
      "Step 12 of epoch 16 completed.\n",
      "Step 13 of epoch 16 completed.\n",
      "Step 14 of epoch 16 completed.\n",
      "Step 15 of epoch 16 completed.\n",
      "Step 16 of epoch 16 completed.\n",
      "Step 17 of epoch 16 completed.\n",
      "Step 0 of epoch 17 completed.\n",
      "Step 1 of epoch 17 completed.\n",
      "Step 2 of epoch 17 completed.\n",
      "Step 3 of epoch 17 completed.\n",
      "Step 4 of epoch 17 completed.\n",
      "Step 5 of epoch 17 completed.\n",
      "Step 6 of epoch 17 completed.\n",
      "Step 7 of epoch 17 completed.\n",
      "Step 8 of epoch 17 completed.\n",
      "Step 9 of epoch 17 completed.\n",
      "Step 10 of epoch 17 completed.\n",
      "Step 11 of epoch 17 completed.\n",
      "Step 12 of epoch 17 completed.\n",
      "Step 13 of epoch 17 completed.\n",
      "Step 14 of epoch 17 completed.\n",
      "Step 15 of epoch 17 completed.\n",
      "Step 16 of epoch 17 completed.\n",
      "Step 17 of epoch 17 completed.\n",
      "Step 0 of epoch 18 completed.\n",
      "Step 1 of epoch 18 completed.\n",
      "Step 2 of epoch 18 completed.\n",
      "Step 3 of epoch 18 completed.\n",
      "Step 4 of epoch 18 completed.\n",
      "Step 5 of epoch 18 completed.\n",
      "Step 6 of epoch 18 completed.\n",
      "Step 7 of epoch 18 completed.\n",
      "Step 8 of epoch 18 completed.\n",
      "Step 9 of epoch 18 completed.\n",
      "Step 10 of epoch 18 completed.\n",
      "Step 11 of epoch 18 completed.\n",
      "Step 12 of epoch 18 completed.\n",
      "Step 13 of epoch 18 completed.\n",
      "Step 14 of epoch 18 completed.\n",
      "Step 15 of epoch 18 completed.\n",
      "Step 16 of epoch 18 completed.\n",
      "Step 17 of epoch 18 completed.\n",
      "Step 0 of epoch 19 completed.\n",
      "Step 1 of epoch 19 completed.\n",
      "Step 2 of epoch 19 completed.\n",
      "Step 3 of epoch 19 completed.\n",
      "Step 4 of epoch 19 completed.\n",
      "Step 5 of epoch 19 completed.\n",
      "Step 6 of epoch 19 completed.\n",
      "Step 7 of epoch 19 completed.\n",
      "Step 8 of epoch 19 completed.\n",
      "Step 9 of epoch 19 completed.\n",
      "Step 10 of epoch 19 completed.\n",
      "Step 11 of epoch 19 completed.\n",
      "Step 12 of epoch 19 completed.\n",
      "Step 13 of epoch 19 completed.\n",
      "Step 14 of epoch 19 completed.\n",
      "Step 15 of epoch 19 completed.\n",
      "Step 16 of epoch 19 completed.\n",
      "Step 17 of epoch 19 completed.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs=20\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Convert your dataset to a DataLoader\n",
    "# Assume `input_ids`, `attention_masks`, and `labels` are your full dataset tensors\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_dataloader = DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=4)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):  # Number of epochs\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Step {step} of epoch {epoch} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f606-6d8b-43b4-b01b-cc51871ff543",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef8e2a7e-f20e-4c8d-9d86-621d72232f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c432683e-965b-4925-b19d-e4222c718fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                 activator of       0.00      0.00      0.00         1\n",
      "       antisense inhibitor of       1.00      0.88      0.94        17\n",
      "regulates (molecular biology)       0.73      1.00      0.84         8\n",
      "\n",
      "                     accuracy                           0.88        26\n",
      "                    macro avg       0.58      0.63      0.59        26\n",
      "                 weighted avg       0.88      0.88      0.87        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernards/sRNA_extraction/srna_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/bernards/sRNA_extraction/srna_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/bernards/sRNA_extraction/srna_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    # Unpack the batch data and move to the device\n",
    "    b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask)\n",
    "\n",
    "    # Move logits to CPU\n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    batch_predictions = np.argmax(logits, axis=1)\n",
    "    predictions.extend(batch_predictions)\n",
    "    true_labels.extend(label_ids)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_labels, predictions, target_names=le.classes_)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f49e9-a518-4d30-b83c-46fc17561f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b766e-29e4-4d4e-bdda-9110f6bd6ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
